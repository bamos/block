import numpy as np
import scipy.sparse.linalg as sla
import scipy.sparse as sp

try:
    import torch
    from torch.autograd import Variable
except:
    pass


import re
from abc import ABCMeta, abstractmethod


def block(rows, dtype=None, arrtype=None):
    if (not _is_list_or_tup(rows)) or len(rows) == 0 or \
       np.any([not _is_list_or_tup(row) for row in rows]):
        raise RuntimeError('''
Unexpected input: Expected a non-empty list of lists.
If you are interested in helping expand the functionality
for your use case please send in an issue or PR at
http://github.com/bamos/block''')

    rowLens = [len(row) for row in rows]
    if len(np.unique(rowLens)) > 1:
        raise RuntimeError('''
Unexpected input: Rows are not the same length.
Row lengths: {}'''.format(rowLens))

    nRows = len(rows)
    nCols = rowLens[0]
    rowSizes = np.zeros(nRows, dtype=int)
    colSizes = np.zeros(nCols, dtype=int)

    backend = _get_backend(rows, dtype, arrtype)

    for i, row in enumerate(rows):
        for j, elem in enumerate(row):
            if backend.is_complete(elem):
                rowSz, colSz = backend.extract_shape(elem)
                rowSizes[i] = rowSz
                colSizes[j] = colSz
            elif hasattr(elem, 'shape'):
                rowSz, colSz = elem.shape
                rowSizes[i] = rowSz
                colSizes[j] = colSz
            elif hasattr(elem, 'size'): 
                rowSz, colSz = elem.size()
                rowSizes[i] = rowSz
                colSizes[j] = colSz

    cRows = []
    for row, rowSz in zip(rows, rowSizes):
        rowSz = int(rowSz)
        if rowSz == 0:
            continue
        cCol = []
        for elem, colSz in zip(row, colSizes):
            colSz = int(colSz)
            if colSz == 0:
                continue
            # TODO: Check types.
            if backend.is_complete(elem):
                cElem = elem
            elif isinstance(elem, float) or isinstance(elem, int):
                cElem = backend.build_full((rowSz, colSz), elem)
            elif isinstance(elem, str):
                if elem == 'I':
                    assert(rowSz == colSz)
                    cElem = backend.build_eye(rowSz)
                elif elem == '-I':
                    assert(rowSz == colSz)
                    cElem = -backend.build_eye(rowSz)
                else:
                    assert(False)
            else:
                cElem = backend.convert(elem)
            cCol.append(cElem)
        cRows.append(cCol)

    return backend.build(cRows)

def block_diag(elems, dtype=None, arrtype=None): 
    n = len(elems)
    return block([[0]*i + [elem] + [0]*(n-1-i) for i,elem in enumerate(elems)],
                 dtype=dtype, arrtype=arrtype)

def _is_list_or_tup(x):
    return isinstance(x, list) or isinstance(x, tuple)


def _get_backend(rows, dtype, arrtype):
    if arrtype == np.ndarray and dtype is not None:
        return NumpyBackend(arrtype, dtype)
    elif arrtype == sla.LinearOperator: 
        return LinearOperatorBackend(dtype)
    elif arrtype is not None and re.search('torch\..*Tensor', arrtype):
        return TorchBackend(arrtype, dtype)
    elif arrtype is not None and re.search('torch\..*Variable', arrtype):
        return TorchVariableBackend(arrtype, dtype)
    else:
        npb = NumpyBackend()
        tb = TorchBackend()
        lob = LinearOperatorBackend()
        tvb = TorchVariableBackend()
        for row in rows:
            for elem in row:
                if npb.is_complete(elem) and elem.size > 0:
                    if dtype is None:
                        dtype = type(elem[0, 0])
                    if arrtype is None:
                        arrtype = type(elem)
                    return NumpyBackend(dtype, arrtype)
                elif tb.is_complete(elem):
                    return TorchBackend(type(elem))
                elif lob.is_complete(elem):
                    return LinearOperatorBackend(elem.dtype)
                elif tvb.is_complete(elem): 
                    return TorchVariableBackend(type(elem.data))

    assert(False)


class Backend():
    __metaclass__=ABCMeta

    @abstractmethod
    def extract_shape(self, x): pass

    @abstractmethod
    def build_eye(self, n): pass

    @abstractmethod
    def build_full(self, shape, fill_val): pass

    @abstractmethod
    def convert(self, x): pass

    @abstractmethod
    def build(self, rows): pass

    @abstractmethod
    def is_complete(self, rows): pass


class NumpyBackend(Backend):

    def __init__(self, dtype=None, arrtype=None):
        self.dtype = dtype
        self.arrtype = arrtype

    def extract_shape(self, x):
        return x.shape

    def build_eye(self, n):
        return np.eye(n)

    def build_full(self, shape, fill_val):
        return np.full(shape, fill_val, self.dtype)

    def convert(self, x):
        assert(False)

    def build(self, rows):
        return np.bmat(rows)

    def is_complete(self, x):
        return isinstance(x, np.ndarray)


class TorchBackend(Backend):

    def __init__(self, dtype=None):
        self.dtype = dtype

    def extract_shape(self, x):
        return x.size()

    def build_eye(self, n):
        return torch.eye(n).type(self.dtype)

    def build_full(self, shape, fill_val):
        return fill_val * torch.ones(*shape).type(self.dtype)

    def convert(self, x):
        assert(False)

    def build(self, rows):
        compRows = []
        for row in rows:
            compRows.append(torch.cat(row, 1))
        return torch.cat(compRows)

    def is_complete(self, x):
        return (re.search('torch\..*Tensor', str(x.__class__)) is not None) \
            and x.ndimension() == 2

class TorchVariableBackend(TorchBackend):
    def build_eye(self, n): 
        return Variable(super().build_eye(n))

    def build_full(self, shape, fill_val): 
        return Variable(super().build_full(shape, fill_val))

    def convert(self, x): 
        if TorchBackend.is_complete(self, x): 
            return Variable(x)

    def is_complete(self, x):
        return re.search('torch\..*Variable', str(x.__class__))

class LinearOperatorBackend(Backend):
    def __init__(self, dtype=None):
        self.dtype = dtype
    
    def extract_shape(self, x): 
        return x.shape
    
    def build_eye(self, n): 
        identity = lambda v: v
        return sla.LinearOperator(shape=(n,n),
                                  matvec=identity, 
                                  rmatvec=identity, 
                                  matmat=identity,
                                  dtype=self.dtype)

    
    def build_full(self, shape, fill_val): 
        m,n = shape
        if fill_val == 0: 
            return shape
        else:
            matvec = lambda v: v.sum()*fill_val*np.ones(m)
            rmatvec = lambda v: v.sum()*fill_val*np.ones(n)
            matmat = lambda M: M.sum(axis=0)*fill_val*np.ones((m,M.shape[1]))
            return sla.LinearOperator(shape=shape,
                                      matvec=matvec, 
                                      rmatvec=rmatvec, 
                                      matmat=matmat,
                                      dtype=self.dtype)
    
    def convert(self, x):
        if (isinstance(x, (np.ndarray, sp.spmatrix))):
            return sla.aslinearoperator(x)
        else: 
            assert(False)

    def build(self, rows):
        col_sizes = [lo.shape[1] if self.is_complete(lo) else lo[1]
                        for lo in rows[0]]
        col_idxs = np.cumsum([0] + col_sizes)
        row_sizes = [row[0].shape[0] if self.is_complete(row[0]) else row[0][0]
                        for row in rows]
        row_idxs = np.cumsum([0] + row_sizes)
        m, n = sum(row_sizes), sum(col_sizes)

        def matvec(v): 
            out = np.zeros(m)
            for row,i,j in zip(rows, row_idxs[:-1], row_idxs[1:]):
                out[i:j] = sum(lo.matvec(v[k:l]) for lo,k,l in 
                                zip(row, col_idxs[:-1], col_idxs[1:])
                                if self.is_complete(lo))
            return out

        # The transposed list
        cols = zip(*rows)
        def rmatvec(v): 
            out = np.zeros(n)
            for col,i,j in zip(cols, col_idxs[:-1], col_idxs[1:]):
                out[i:j] = sum(lo.rmatvec(v[k:l]) for lo,k,l in 
                                zip(col, row_idxs[:-1], row_idxs[1:])
                                if self.is_complete(lo))
            return out

        def matmat(M): 
            out = np.zeros((m, M.shape[1]))
            for row,i,j in zip(rows, row_idxs[:-1], row_idxs[1:]):
                out[i:j] = sum(lo.matmat(M[k:l]) for lo,k,l in 
                                zip(row, col_idxs[:-1], col_idxs[1:])
                                if self.is_complete(lo))
            return out

        return sla.LinearOperator(shape=(m,n),
                                  matvec=matvec, 
                                  rmatvec=rmatvec, 
                                  matmat=matmat,
                                  dtype=self.dtype)

    
    def is_complete(self, x): 
        return isinstance(x, sla.LinearOperator)
